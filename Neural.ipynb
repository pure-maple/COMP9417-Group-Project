{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.regularizers import l1_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create model. feature_dim =103, label_dim =11\n",
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_151 (Dense)            (None, 500)               52000     \n",
      "_________________________________________________________________\n",
      "dense_152 (Dense)            (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dense_153 (Dense)            (None, 11)                1111      \n",
      "=================================================================\n",
      "Total params: 103,211\n",
      "Trainable params: 103,211\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 5.8847 - accuracy: 0.0625 - precision_6: 0.3250 - recall_8: 0.5417Epoch 1 F1 score: 0.1660\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.2319 - accuracy: 0.0804 - precision_6: 0.2691 - recall_8: 0.1747 - val_loss: 0.6629 - val_accuracy: 0.0543 - val_precision_6: 0.2567 - val_recall_8: 0.2023\n",
      "Epoch 2/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.6493 - accuracy: 0.1250 - precision_6: 0.3243 - recall_8: 0.2609Epoch 2 F1 score: 0.0979\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.6363 - accuracy: 0.0817 - precision_6: 0.2888 - recall_8: 0.1149 - val_loss: 0.6430 - val_accuracy: 0.1141 - val_precision_6: 0.2633 - val_recall_8: 0.1426\n",
      "Epoch 3/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.7175 - accuracy: 0.0000e+00 - precision_6: 0.3077 - recall_8: 0.1569Epoch 3 F1 score: 0.0561\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.6160 - accuracy: 0.1213 - precision_6: 0.3426 - recall_8: 0.1245 - val_loss: 0.6459 - val_accuracy: 0.1359 - val_precision_6: 0.4583 - val_recall_8: 0.0424\n",
      "Epoch 4/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.7250 - accuracy: 0.1250 - precision_6: 0.5000 - recall_8: 0.0339Epoch 4 F1 score: 0.1091\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.6279 - accuracy: 0.0790 - precision_6: 0.3345 - recall_8: 0.1385 - val_loss: 0.6109 - val_accuracy: 0.0761 - val_precision_6: 0.3592 - val_recall_8: 0.1965\n",
      "Epoch 5/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.5909 - accuracy: 0.0625 - precision_6: 0.3600 - recall_8: 0.1875Epoch 5 F1 score: 0.1243\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.5970 - accuracy: 0.1199 - precision_6: 0.3561 - recall_8: 0.0931 - val_loss: 0.6325 - val_accuracy: 0.2174 - val_precision_6: 0.2814 - val_recall_8: 0.1599\n",
      "Epoch 6/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.5998 - accuracy: 0.2500 - precision_6: 0.3333 - recall_8: 0.1707Epoch 6 F1 score: 0.1123\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.6003 - accuracy: 0.1267 - precision_6: 0.3950 - recall_8: 0.1361 - val_loss: 0.6212 - val_accuracy: 0.1522 - val_precision_6: 0.3566 - val_recall_8: 0.0983\n",
      "Epoch 7/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.6487 - accuracy: 0.3125 - precision_6: 0.6000 - recall_8: 0.1053Epoch 7 F1 score: 0.1039\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.5862 - accuracy: 0.1403 - precision_6: 0.3886 - recall_8: 0.1347 - val_loss: 0.6143 - val_accuracy: 0.1033 - val_precision_6: 0.3516 - val_recall_8: 0.1233\n",
      "Epoch 8/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.5895 - accuracy: 0.0625 - precision_6: 0.4400 - recall_8: 0.2157Epoch 8 F1 score: 0.0614\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.5933 - accuracy: 0.1172 - precision_6: 0.4263 - recall_8: 0.1438 - val_loss: 0.6392 - val_accuracy: 0.0272 - val_precision_6: 0.2228 - val_recall_8: 0.0867\n",
      "Epoch 9/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.6122 - accuracy: 0.0000e+00 - precision_6: 0.3333 - recall_8: 0.1250Epoch 9 F1 score: 0.0836\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.5773 - accuracy: 0.1417 - precision_6: 0.4410 - recall_8: 0.1424 - val_loss: 0.6294 - val_accuracy: 0.1033 - val_precision_6: 0.3873 - val_recall_8: 0.1060\n",
      "Epoch 10/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.5476 - accuracy: 0.0625 - precision_6: 0.4000 - recall_8: 0.0952Epoch 10 F1 score: 0.1441\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.5677 - accuracy: 0.1635 - precision_6: 0.4489 - recall_8: 0.1125 - val_loss: 0.6656 - val_accuracy: 0.2283 - val_precision_6: 0.2733 - val_recall_8: 0.2486\n",
      "Epoch 11/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.5938 - accuracy: 0.4375 - precision_6: 0.3261 - recall_8: 0.3333Epoch 11 F1 score: 0.0254\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.5700 - accuracy: 0.1444 - precision_6: 0.4355 - recall_8: 0.1433 - val_loss: 0.6143 - val_accuracy: 0.1304 - val_precision_6: 0.2571 - val_recall_8: 0.0173\n",
      "Epoch 12/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.7173 - accuracy: 0.2500 - precision_6: 1.0000 - recall_8: 0.0323Epoch 12 F1 score: 0.0828\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.5556 - accuracy: 0.1526 - precision_6: 0.4759 - recall_8: 0.1337 - val_loss: 0.6108 - val_accuracy: 0.2011 - val_precision_6: 0.2870 - val_recall_8: 0.0636\n",
      "Epoch 13/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.6264 - accuracy: 0.2500 - precision_6: 0.4286 - recall_8: 0.0638Epoch 13 F1 score: 0.1186\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.5603 - accuracy: 0.1499 - precision_6: 0.4604 - recall_8: 0.1236 - val_loss: 0.6113 - val_accuracy: 0.1793 - val_precision_6: 0.3017 - val_recall_8: 0.1407\n",
      "Epoch 14/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.4702 - accuracy: 0.1875 - precision_6: 0.5714 - recall_8: 0.2927Epoch 14 F1 score: 0.1066\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.5577 - accuracy: 0.1608 - precision_6: 0.5120 - recall_8: 0.1438 - val_loss: 0.6103 - val_accuracy: 0.1141 - val_precision_6: 0.3388 - val_recall_8: 0.0790\n",
      "Epoch 15/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.5667 - accuracy: 0.1250 - precision_6: 0.6111 - recall_8: 0.2444Epoch 15 F1 score: 0.0783\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.5521 - accuracy: 0.1349 - precision_6: 0.5094 - recall_8: 0.1303 - val_loss: 0.6041 - val_accuracy: 0.0543 - val_precision_6: 0.3164 - val_recall_8: 0.1079\n",
      "Epoch 16/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.5173 - accuracy: 0.1875 - precision_6: 0.7500 - recall_8: 0.2727Epoch 16 F1 score: 0.1379\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.5519 - accuracy: 0.1458 - precision_6: 0.5301 - recall_8: 0.1530 - val_loss: 0.6121 - val_accuracy: 0.0435 - val_precision_6: 0.2882 - val_recall_8: 0.1599\n",
      "Epoch 17/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.5348 - accuracy: 0.0625 - precision_6: 0.4333 - recall_8: 0.3095Epoch 17 F1 score: 0.0649\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.5496 - accuracy: 0.1499 - precision_6: 0.4664 - recall_8: 0.1342 - val_loss: 0.6152 - val_accuracy: 0.0978 - val_precision_6: 0.2911 - val_recall_8: 0.0443\n",
      "Epoch 18/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.5910 - accuracy: 0.1875 - precision_6: 0.5000 - recall_8: 0.1064Epoch 18 F1 score: 0.0354\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.5550 - accuracy: 0.1444 - precision_6: 0.4763 - recall_8: 0.1554 - val_loss: 0.5950 - val_accuracy: 0.1467 - val_precision_6: 0.2727 - val_recall_8: 0.0231\n",
      "Epoch 19/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.5028 - accuracy: 0.2500 - precision_6: 0.8000 - recall_8: 0.0889Epoch 19 F1 score: 0.1061\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.1621 - precision_6: 0.5272 - recall_8: 0.1728 - val_loss: 0.6246 - val_accuracy: 0.0924 - val_precision_6: 0.2849 - val_recall_8: 0.0944\n",
      "Epoch 20/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.5602 - accuracy: 0.1875 - precision_6: 0.5500 - recall_8: 0.2115Epoch 20 F1 score: 0.0718\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.5448 - accuracy: 0.1662 - precision_6: 0.4920 - recall_8: 0.1626 - val_loss: 0.6389 - val_accuracy: 0.0163 - val_precision_6: 0.2047 - val_recall_8: 0.0848\n",
      "Epoch 21/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.5759 - accuracy: 0.0000e+00 - precision_6: 0.4286 - recall_8: 0.1304Epoch 21 F1 score: 0.0556\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.5383 - accuracy: 0.1349 - precision_6: 0.5118 - recall_8: 0.1255 - val_loss: 0.6152 - val_accuracy: 0.1359 - val_precision_6: 0.3860 - val_recall_8: 0.0424\n",
      "Epoch 22/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.5470 - accuracy: 0.2500 - precision_6: 0.7500 - recall_8: 0.0682Epoch 22 F1 score: 0.0523\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.5350 - accuracy: 0.1608 - precision_6: 0.5620 - recall_8: 0.1641 - val_loss: 0.6156 - val_accuracy: 0.1141 - val_precision_6: 0.3400 - val_recall_8: 0.0328\n",
      "Epoch 23/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.6104 - accuracy: 0.1250 - precision_6: 0.8571 - recall_8: 0.1091Epoch 23 F1 score: 0.0644\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.1717 - precision_6: 0.5208 - recall_8: 0.1573 - val_loss: 0.5984 - val_accuracy: 0.0924 - val_precision_6: 0.3077 - val_recall_8: 0.0462\n",
      "Epoch 24/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.5869 - accuracy: 0.0625 - precision_6: 0.7273 - recall_8: 0.1356Epoch 24 F1 score: 0.1301\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.5381 - accuracy: 0.1676 - precision_6: 0.5242 - recall_8: 0.1569 - val_loss: 0.6150 - val_accuracy: 0.0870 - val_precision_6: 0.2959 - val_recall_8: 0.1118\n",
      "Epoch 25/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.5141 - accuracy: 0.0000e+00 - precision_6: 0.3636 - recall_8: 0.2051Epoch 25 F1 score: 0.0956\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.1676 - precision_6: 0.5886 - recall_8: 0.1795 - val_loss: 0.6166 - val_accuracy: 0.1848 - val_precision_6: 0.3092 - val_recall_8: 0.0906\n",
      "Epoch 26/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.5846 - accuracy: 0.2500 - precision_6: 0.4545 - recall_8: 0.2041Epoch 26 F1 score: 0.0646\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.5272 - accuracy: 0.1689 - precision_6: 0.5596 - recall_8: 0.1723 - val_loss: 0.6042 - val_accuracy: 0.1087 - val_precision_6: 0.2500 - val_recall_8: 0.0482\n",
      "Epoch 27/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.5239 - accuracy: 0.3125 - precision_6: 0.6667 - recall_8: 0.1000Epoch 27 F1 score: 0.0744\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.1717 - precision_6: 0.5681 - recall_8: 0.1771 - val_loss: 0.5978 - val_accuracy: 0.1033 - val_precision_6: 0.3944 - val_recall_8: 0.0539\n",
      "Epoch 28/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.4548 - accuracy: 0.1250 - precision_6: 0.8182 - recall_8: 0.2195Epoch 28 F1 score: 0.0929\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.5230 - accuracy: 0.1785 - precision_6: 0.5894 - recall_8: 0.1670 - val_loss: 0.6244 - val_accuracy: 0.0978 - val_precision_6: 0.2971 - val_recall_8: 0.1002\n",
      "Epoch 29/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.6209 - accuracy: 0.2500 - precision_6: 0.6000 - recall_8: 0.1667Epoch 29 F1 score: 0.0807\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.1621 - precision_6: 0.5814 - recall_8: 0.1810 - val_loss: 0.6292 - val_accuracy: 0.0924 - val_precision_6: 0.2735 - val_recall_8: 0.0617\n",
      "Epoch 30/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.5253 - accuracy: 0.1250 - precision_6: 0.4444 - recall_8: 0.1905Epoch 30 F1 score: 0.1137\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.1962 - precision_6: 0.5703 - recall_8: 0.2114 - val_loss: 0.6054 - val_accuracy: 0.1033 - val_precision_6: 0.3298 - val_recall_8: 0.1214\n",
      "Epoch 31/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.5205 - accuracy: 0.2500 - precision_6: 0.5000 - recall_8: 0.1250Epoch 31 F1 score: 0.0909\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.5230 - accuracy: 0.1717 - precision_6: 0.5683 - recall_8: 0.1906 - val_loss: 0.6117 - val_accuracy: 0.1793 - val_precision_6: 0.2708 - val_recall_8: 0.0751\n",
      "Epoch 32/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.6177 - accuracy: 0.1875 - precision_6: 0.8000 - recall_8: 0.2388Epoch 32 F1 score: 0.1252\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.2112 - precision_6: 0.5915 - recall_8: 0.1887 - val_loss: 0.6279 - val_accuracy: 0.1359 - val_precision_6: 0.2922 - val_recall_8: 0.1233\n",
      "Epoch 33/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.5197 - accuracy: 0.1875 - precision_6: 0.5789 - recall_8: 0.2340Epoch 33 F1 score: 0.1141\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.1853 - precision_6: 0.6213 - recall_8: 0.1829 - val_loss: 0.6231 - val_accuracy: 0.0707 - val_precision_6: 0.3240 - val_recall_8: 0.1118\n",
      "Epoch 34/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.5042 - accuracy: 0.0000e+00 - precision_6: 0.5000 - recall_8: 0.1892Epoch 34 F1 score: 0.0858\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.1948 - precision_6: 0.6329 - recall_8: 0.1931 - val_loss: 0.6069 - val_accuracy: 0.1141 - val_precision_6: 0.3426 - val_recall_8: 0.0713\n",
      "Epoch 35/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.4156 - accuracy: 0.3750 - precision_6: 0.8261 - recall_8: 0.3878Epoch 35 F1 score: 0.1924\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.1839 - precision_6: 0.6129 - recall_8: 0.2148 - val_loss: 0.6911 - val_accuracy: 0.2065 - val_precision_6: 0.2834 - val_recall_8: 0.2659\n",
      "Epoch 36/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.5953 - accuracy: 0.5625 - precision_6: 0.5000 - recall_8: 0.3636Epoch 36 F1 score: 0.1566\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.2030 - precision_6: 0.6003 - recall_8: 0.2210 - val_loss: 0.6371 - val_accuracy: 0.1250 - val_precision_6: 0.3072 - val_recall_8: 0.1888\n",
      "Epoch 37/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.5471 - accuracy: 0.1250 - precision_6: 0.5000 - recall_8: 0.2558Epoch 37 F1 score: 0.1197\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4992 - accuracy: 0.1880 - precision_6: 0.6542 - recall_8: 0.2119 - val_loss: 0.6339 - val_accuracy: 0.1196 - val_precision_6: 0.2755 - val_recall_8: 0.1040\n",
      "Epoch 38/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.5266 - accuracy: 0.2500 - precision_6: 0.5652 - recall_8: 0.2653Epoch 38 F1 score: 0.0918\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.1812 - precision_6: 0.6440 - recall_8: 0.2375 - val_loss: 0.6253 - val_accuracy: 0.0652 - val_precision_6: 0.2973 - val_recall_8: 0.0848\n",
      "Epoch 39/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.5341 - accuracy: 0.1250 - precision_6: 0.6000 - recall_8: 0.1957Epoch 39 F1 score: 0.1333\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.2166 - precision_6: 0.6205 - recall_8: 0.2336 - val_loss: 0.6296 - val_accuracy: 0.0489 - val_precision_6: 0.3048 - val_recall_8: 0.1098\n",
      "Epoch 40/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.4173 - accuracy: 0.1250 - precision_6: 0.5556 - recall_8: 0.2941Epoch 40 F1 score: 0.0966\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4916 - accuracy: 0.2166 - precision_6: 0.6624 - recall_8: 0.2510 - val_loss: 0.6209 - val_accuracy: 0.0978 - val_precision_6: 0.3514 - val_recall_8: 0.0751\n",
      "Epoch 41/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.4036 - accuracy: 0.1875 - precision_6: 1.0000 - recall_8: 0.3171Epoch 41 F1 score: 0.1398\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.2084 - precision_6: 0.6613 - recall_8: 0.2582 - val_loss: 0.6433 - val_accuracy: 0.0598 - val_precision_6: 0.3146 - val_recall_8: 0.1618\n",
      "Epoch 42/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.5563 - accuracy: 0.0000e+00 - precision_6: 0.5417 - recall_8: 0.2500Epoch 42 F1 score: 0.1244\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.1880 - precision_6: 0.6015 - recall_8: 0.2389 - val_loss: 0.6240 - val_accuracy: 0.1359 - val_precision_6: 0.3409 - val_recall_8: 0.1445\n",
      "Epoch 43/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.5247 - accuracy: 0.3750 - precision_6: 0.6400 - recall_8: 0.3077Epoch 43 F1 score: 0.0908\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4929 - accuracy: 0.2057 - precision_6: 0.6210 - recall_8: 0.2514 - val_loss: 0.6416 - val_accuracy: 0.0761 - val_precision_6: 0.3761 - val_recall_8: 0.0790\n",
      "Epoch 44/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.5503 - accuracy: 0.1875 - precision_6: 0.6364 - recall_8: 0.1373Epoch 44 F1 score: 0.0811\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.2112 - precision_6: 0.6624 - recall_8: 0.2510 - val_loss: 0.6499 - val_accuracy: 0.1250 - val_precision_6: 0.2357 - val_recall_8: 0.0713\n",
      "Epoch 45/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.4631 - accuracy: 0.4375 - precision_6: 0.6667 - recall_8: 0.1667Epoch 45 F1 score: 0.1060\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.2439 - precision_6: 0.6802 - recall_8: 0.2823 - val_loss: 0.6223 - val_accuracy: 0.1087 - val_precision_6: 0.3435 - val_recall_8: 0.0867\n",
      "Epoch 46/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.4291 - accuracy: 0.3125 - precision_6: 0.5789 - recall_8: 0.2750Epoch 46 F1 score: 0.0663\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.2139 - precision_6: 0.6881 - recall_8: 0.2736 - val_loss: 0.6203 - val_accuracy: 0.1359 - val_precision_6: 0.2843 - val_recall_8: 0.0559\n",
      "Epoch 47/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.4688 - accuracy: 0.1250 - precision_6: 0.4000 - recall_8: 0.0526Epoch 47 F1 score: 0.1046\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.2180 - precision_6: 0.6858 - recall_8: 0.2823 - val_loss: 0.6481 - val_accuracy: 0.0652 - val_precision_6: 0.3187 - val_recall_8: 0.1118\n",
      "Epoch 48/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.4347 - accuracy: 0.1875 - precision_6: 0.7857 - recall_8: 0.4889Epoch 48 F1 score: 0.1522\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.1962 - precision_6: 0.6655 - recall_8: 0.2756 - val_loss: 0.6417 - val_accuracy: 0.1250 - val_precision_6: 0.3169 - val_recall_8: 0.1484\n",
      "Epoch 49/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.4472 - accuracy: 0.1875 - precision_6: 0.5909 - recall_8: 0.3250Epoch 49 F1 score: 0.1141\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.2330 - precision_6: 0.6836 - recall_8: 0.2857 - val_loss: 0.6443 - val_accuracy: 0.0761 - val_precision_6: 0.2722 - val_recall_8: 0.0886\n",
      "Epoch 50/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.5549 - accuracy: 0.1250 - precision_6: 0.6250 - recall_8: 0.2041Epoch 50 F1 score: 0.1241\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.2371 - precision_6: 0.7110 - recall_8: 0.3016 - val_loss: 0.6458 - val_accuracy: 0.0870 - val_precision_6: 0.2882 - val_recall_8: 0.0944\n",
      "Epoch 51/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.4487 - accuracy: 0.2500 - precision_6: 0.7391 - recall_8: 0.3469Epoch 51 F1 score: 0.1162\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.2371 - precision_6: 0.6988 - recall_8: 0.3045 - val_loss: 0.6604 - val_accuracy: 0.2011 - val_precision_6: 0.3052 - val_recall_8: 0.1252\n",
      "Epoch 52/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.4795 - accuracy: 0.3750 - precision_6: 0.6667 - recall_8: 0.3673Epoch 52 F1 score: 0.0855\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.2493 - precision_6: 0.6726 - recall_8: 0.3113 - val_loss: 0.6380 - val_accuracy: 0.1033 - val_precision_6: 0.3486 - val_recall_8: 0.0732\n",
      "Epoch 53/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.4735 - accuracy: 0.2500 - precision_6: 0.7500 - recall_8: 0.2667Epoch 53 F1 score: 0.1360\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4598 - accuracy: 0.2166 - precision_6: 0.6888 - recall_8: 0.3098 - val_loss: 0.6507 - val_accuracy: 0.0815 - val_precision_6: 0.2985 - val_recall_8: 0.1156\n",
      "Epoch 54/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.4505 - accuracy: 0.2500 - precision_6: 0.7778 - recall_8: 0.4200Epoch 54 F1 score: 0.1217\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.2371 - precision_6: 0.6891 - recall_8: 0.3166 - val_loss: 0.6625 - val_accuracy: 0.1793 - val_precision_6: 0.2684 - val_recall_8: 0.0983\n",
      "Epoch 55/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.4116 - accuracy: 0.2500 - precision_6: 0.6842 - recall_8: 0.3250Epoch 55 F1 score: 0.0887\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4486 - accuracy: 0.2248 - precision_6: 0.7160 - recall_8: 0.3359 - val_loss: 0.6417 - val_accuracy: 0.0815 - val_precision_6: 0.3391 - val_recall_8: 0.0751\n",
      "Epoch 56/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.4177 - accuracy: 0.2500 - precision_6: 0.8421 - recall_8: 0.3404Epoch 56 F1 score: 0.1415\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.2411 - precision_6: 0.6948 - recall_8: 0.3263 - val_loss: 0.6429 - val_accuracy: 0.1304 - val_precision_6: 0.3349 - val_recall_8: 0.1368\n",
      "Epoch 57/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.4379 - accuracy: 0.4375 - precision_6: 0.7778 - recall_8: 0.3111Epoch 57 F1 score: 0.1982\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4498 - accuracy: 0.2452 - precision_6: 0.7107 - recall_8: 0.3378 - val_loss: 0.6512 - val_accuracy: 0.1304 - val_precision_6: 0.2805 - val_recall_8: 0.1908\n",
      "Epoch 58/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.3931 - accuracy: 0.1875 - precision_6: 0.6250 - recall_8: 0.5405Epoch 58 F1 score: 0.1271\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4471 - accuracy: 0.2411 - precision_6: 0.7009 - recall_8: 0.3494 - val_loss: 0.6636 - val_accuracy: 0.0489 - val_precision_6: 0.3027 - val_recall_8: 0.1079\n",
      "Epoch 59/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.4496 - accuracy: 0.0625 - precision_6: 0.5833 - recall_8: 0.1707Epoch 59 F1 score: 0.1152\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.2452 - precision_6: 0.6893 - recall_8: 0.3330 - val_loss: 0.6474 - val_accuracy: 0.1630 - val_precision_6: 0.2930 - val_recall_8: 0.0886\n",
      "Epoch 60/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.3799 - accuracy: 0.2500 - precision_6: 0.8421 - recall_8: 0.3721Epoch 60 F1 score: 0.1679\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.2561 - precision_6: 0.7038 - recall_8: 0.3692 - val_loss: 0.6479 - val_accuracy: 0.1196 - val_precision_6: 0.3000 - val_recall_8: 0.1561\n",
      "Epoch 61/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.4021 - accuracy: 0.5000 - precision_6: 0.7619 - recall_8: 0.3636Epoch 61 F1 score: 0.1878\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.2684 - precision_6: 0.7196 - recall_8: 0.3629 - val_loss: 0.6778 - val_accuracy: 0.0543 - val_precision_6: 0.3244 - val_recall_8: 0.2100\n",
      "Epoch 62/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.4413 - accuracy: 0.0625 - precision_6: 0.3810 - recall_8: 0.2500Epoch 62 F1 score: 0.0993\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.2520 - precision_6: 0.6813 - recall_8: 0.3591 - val_loss: 0.6667 - val_accuracy: 0.0978 - val_precision_6: 0.3185 - val_recall_8: 0.0963\n",
      "Epoch 63/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.3975 - accuracy: 0.2500 - precision_6: 0.9412 - recall_8: 0.3721Epoch 63 F1 score: 0.1910\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.2725 - precision_6: 0.7424 - recall_8: 0.3518 - val_loss: 0.6578 - val_accuracy: 0.0978 - val_precision_6: 0.2823 - val_recall_8: 0.1811\n",
      "Epoch 64/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.4296 - accuracy: 0.1875 - precision_6: 0.5882 - recall_8: 0.5128Epoch 64 F1 score: 0.1457\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.2902 - precision_6: 0.7151 - recall_8: 0.3851 - val_loss: 0.6908 - val_accuracy: 0.1413 - val_precision_6: 0.2681 - val_recall_8: 0.1214\n",
      "Epoch 65/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.4285 - accuracy: 0.3125 - precision_6: 0.7500 - recall_8: 0.4200Epoch 65 F1 score: 0.1958\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.2534 - precision_6: 0.7333 - recall_8: 0.3967 - val_loss: 0.6725 - val_accuracy: 0.1522 - val_precision_6: 0.3031 - val_recall_8: 0.1869\n",
      "Epoch 66/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.3996 - accuracy: 0.2500 - precision_6: 0.7750 - recall_8: 0.5962Epoch 66 F1 score: 0.1650\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.2875 - precision_6: 0.7481 - recall_8: 0.3885 - val_loss: 0.6740 - val_accuracy: 0.1630 - val_precision_6: 0.2837 - val_recall_8: 0.1541\n",
      "Epoch 67/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.4069 - accuracy: 0.1250 - precision_6: 0.7805 - recall_8: 0.5926Epoch 67 F1 score: 0.1368\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.2902 - precision_6: 0.7235 - recall_8: 0.4015 - val_loss: 0.6799 - val_accuracy: 0.0870 - val_precision_6: 0.3069 - val_recall_8: 0.1195\n",
      "Epoch 68/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.4155 - accuracy: 0.1250 - precision_6: 0.7097 - recall_8: 0.4783Epoch 68 F1 score: 0.1091\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4208 - accuracy: 0.2589 - precision_6: 0.7409 - recall_8: 0.4126 - val_loss: 0.6712 - val_accuracy: 0.1087 - val_precision_6: 0.2922 - val_recall_8: 0.0867\n",
      "Epoch 69/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.3432 - accuracy: 0.4375 - precision_6: 1.0000 - recall_8: 0.3030Epoch 69 F1 score: 0.1434\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.2970 - precision_6: 0.7509 - recall_8: 0.4102 - val_loss: 0.6838 - val_accuracy: 0.1250 - val_precision_6: 0.2910 - val_recall_8: 0.1060\n",
      "Epoch 70/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.3517 - accuracy: 0.5000 - precision_6: 0.7143 - recall_8: 0.2857Epoch 70 F1 score: 0.1873\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4040 - accuracy: 0.2670 - precision_6: 0.7543 - recall_8: 0.4223 - val_loss: 0.7008 - val_accuracy: 0.1033 - val_precision_6: 0.2957 - val_recall_8: 0.1869\n",
      "Epoch 71/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.3974 - accuracy: 0.1875 - precision_6: 0.6452 - recall_8: 0.4878Epoch 71 F1 score: 0.1573\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4037 - accuracy: 0.2820 - precision_6: 0.7561 - recall_8: 0.4339 - val_loss: 0.6971 - val_accuracy: 0.1413 - val_precision_6: 0.3162 - val_recall_8: 0.1541\n",
      "Epoch 72/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.3550 - accuracy: 0.5625 - precision_6: 0.7143 - recall_8: 0.4167Epoch 72 F1 score: 0.1738\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4046 - accuracy: 0.2752 - precision_6: 0.7502 - recall_8: 0.4305 - val_loss: 0.6889 - val_accuracy: 0.1033 - val_precision_6: 0.2984 - val_recall_8: 0.1484\n",
      "Epoch 73/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.4428 - accuracy: 0.2500 - precision_6: 0.8077 - recall_8: 0.4468Epoch 73 F1 score: 0.1707\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.3947 - accuracy: 0.2984 - precision_6: 0.7636 - recall_8: 0.4459 - val_loss: 0.7048 - val_accuracy: 0.0870 - val_precision_6: 0.3168 - val_recall_8: 0.1599\n",
      "Epoch 74/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.3991 - accuracy: 0.1250 - precision_6: 0.7297 - recall_8: 0.5294Epoch 74 F1 score: 0.1608\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.3913 - accuracy: 0.2956 - precision_6: 0.7694 - recall_8: 0.4638 - val_loss: 0.7090 - val_accuracy: 0.0870 - val_precision_6: 0.2885 - val_recall_8: 0.1407\n",
      "Epoch 75/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.4563 - accuracy: 0.3125 - precision_6: 0.7917 - recall_8: 0.3654Epoch 75 F1 score: 0.1621\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.3914 - accuracy: 0.2888 - precision_6: 0.7750 - recall_8: 0.4604 - val_loss: 0.7336 - val_accuracy: 0.1087 - val_precision_6: 0.3080 - val_recall_8: 0.1638\n",
      "Epoch 76/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.3652 - accuracy: 0.2500 - precision_6: 0.8333 - recall_8: 0.5319Epoch 76 F1 score: 0.1863\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.3860 - accuracy: 0.2984 - precision_6: 0.7685 - recall_8: 0.4807 - val_loss: 0.7429 - val_accuracy: 0.1033 - val_precision_6: 0.2922 - val_recall_8: 0.1734\n",
      "Epoch 77/200\n",
      "27/46 [================>.............] - ETA: 0s - loss: 0.3739 - accuracy: 0.3079 - precision_6: 0.7768 - recall_8: 0.4946Epoch 77 F1 score: 0.1814\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3850 - accuracy: 0.3093 - precision_6: 0.7682 - recall_8: 0.4846 - val_loss: 0.7237 - val_accuracy: 0.0978 - val_precision_6: 0.3118 - val_recall_8: 0.1676\n",
      "Epoch 78/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.3662 - accuracy: 0.0625 - precision_6: 0.6400 - recall_8: 0.3902Epoch 78 F1 score: 0.1635\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.3836 - accuracy: 0.2970 - precision_6: 0.7840 - recall_8: 0.4696 - val_loss: 0.7165 - val_accuracy: 0.1087 - val_precision_6: 0.3062 - val_recall_8: 0.1522\n",
      "Epoch 79/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.2927 - accuracy: 0.5625 - precision_6: 0.8800 - recall_8: 0.5238Epoch 79 F1 score: 0.1676\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3787 - accuracy: 0.3120 - precision_6: 0.7702 - recall_8: 0.4884 - val_loss: 0.7119 - val_accuracy: 0.0652 - val_precision_6: 0.3027 - val_recall_8: 0.1522\n",
      "Epoch 80/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.3973 - accuracy: 0.0625 - precision_6: 0.8148 - recall_8: 0.4400Epoch 80 F1 score: 0.2061\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3746 - accuracy: 0.2861 - precision_6: 0.7808 - recall_8: 0.5019 - val_loss: 0.7149 - val_accuracy: 0.0978 - val_precision_6: 0.3112 - val_recall_8: 0.2081\n",
      "Epoch 81/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.4366 - accuracy: 0.1875 - precision_6: 0.5946 - recall_8: 0.4889Epoch 81 F1 score: 0.2269\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.3715 - accuracy: 0.3038 - precision_6: 0.7852 - recall_8: 0.5063 - val_loss: 0.7224 - val_accuracy: 0.1033 - val_precision_6: 0.3023 - val_recall_8: 0.2004\n",
      "Epoch 82/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.3787 - accuracy: 0.3750 - precision_6: 0.5897 - recall_8: 0.6216Epoch 82 F1 score: 0.1894\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3709 - accuracy: 0.2834 - precision_6: 0.7747 - recall_8: 0.5111 - val_loss: 0.7489 - val_accuracy: 0.1413 - val_precision_6: 0.2922 - val_recall_8: 0.1869\n",
      "Epoch 83/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.4073 - accuracy: 0.3125 - precision_6: 0.7143 - recall_8: 0.4167Epoch 83 F1 score: 0.1930\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3640 - accuracy: 0.2847 - precision_6: 0.7899 - recall_8: 0.5261 - val_loss: 0.7421 - val_accuracy: 0.1141 - val_precision_6: 0.3029 - val_recall_8: 0.1599\n",
      "Epoch 84/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.3255 - accuracy: 0.6250 - precision_6: 0.8182 - recall_8: 0.4615Epoch 84 F1 score: 0.2282\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.3623 - accuracy: 0.3093 - precision_6: 0.7823 - recall_8: 0.5256 - val_loss: 0.7447 - val_accuracy: 0.0978 - val_precision_6: 0.3094 - val_recall_8: 0.2408\n",
      "Epoch 85/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.3026 - accuracy: 0.2500 - precision_6: 0.7500 - recall_8: 0.7105Epoch 85 F1 score: 0.1905\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3565 - accuracy: 0.3025 - precision_6: 0.7905 - recall_8: 0.5391 - val_loss: 0.7439 - val_accuracy: 0.0978 - val_precision_6: 0.2959 - val_recall_8: 0.1676\n",
      "Epoch 86/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.3748 - accuracy: 0.2500 - precision_6: 0.7222 - recall_8: 0.3421Epoch 86 F1 score: 0.1788\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.3065 - precision_6: 0.7822 - recall_8: 0.5391 - val_loss: 0.7473 - val_accuracy: 0.1033 - val_precision_6: 0.2966 - val_recall_8: 0.1349\n",
      "Epoch 87/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.3119 - accuracy: 0.4375 - precision_6: 0.9630 - recall_8: 0.5306Epoch 87 F1 score: 0.2030\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3485 - accuracy: 0.3229 - precision_6: 0.8003 - recall_8: 0.5492 - val_loss: 0.7463 - val_accuracy: 0.1359 - val_precision_6: 0.3099 - val_recall_8: 0.1869\n",
      "Epoch 88/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.2944 - accuracy: 0.4375 - precision_6: 0.8889 - recall_8: 0.6531Epoch 88 F1 score: 0.2131\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.3408 - accuracy: 0.3324 - precision_6: 0.8008 - recall_8: 0.5608 - val_loss: 0.7732 - val_accuracy: 0.1359 - val_precision_6: 0.2963 - val_recall_8: 0.2004\n",
      "Epoch 89/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.3750 - accuracy: 0.3125 - precision_6: 0.8750 - recall_8: 0.4773Epoch 89 F1 score: 0.2397\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.3373 - accuracy: 0.3324 - precision_6: 0.8188 - recall_8: 0.5516 - val_loss: 0.7762 - val_accuracy: 0.1522 - val_precision_6: 0.2982 - val_recall_8: 0.2293\n",
      "Epoch 90/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.3160 - accuracy: 0.3750 - precision_6: 0.8750 - recall_8: 0.6731Epoch 90 F1 score: 0.2275\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.3342 - accuracy: 0.3215 - precision_6: 0.8008 - recall_8: 0.5801 - val_loss: 0.7920 - val_accuracy: 0.1141 - val_precision_6: 0.3151 - val_recall_8: 0.2216\n",
      "Epoch 91/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.2333 - accuracy: 0.4375 - precision_6: 0.8571 - recall_8: 0.7692Epoch 91 F1 score: 0.2076\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.3375 - accuracy: 0.3311 - precision_6: 0.8154 - recall_8: 0.5734 - val_loss: 0.7857 - val_accuracy: 0.0924 - val_precision_6: 0.3170 - val_recall_8: 0.2119\n",
      "Epoch 92/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.2774 - accuracy: 0.3750 - precision_6: 0.7931 - recall_8: 0.6571Epoch 92 F1 score: 0.2176\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.3188 - precision_6: 0.7999 - recall_8: 0.5864 - val_loss: 0.8085 - val_accuracy: 0.1196 - val_precision_6: 0.2823 - val_recall_8: 0.2062\n",
      "Epoch 93/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.3090 - accuracy: 0.5000 - precision_6: 0.8056 - recall_8: 0.6591Epoch 93 F1 score: 0.2458\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.3365 - precision_6: 0.8153 - recall_8: 0.6052 - val_loss: 0.8077 - val_accuracy: 0.1033 - val_precision_6: 0.3016 - val_recall_8: 0.2505\n",
      "Epoch 94/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.3001 - accuracy: 0.2500 - precision_6: 0.7455 - recall_8: 0.7885Epoch 94 F1 score: 0.2143\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.3474 - precision_6: 0.8112 - recall_8: 0.5888 - val_loss: 0.8110 - val_accuracy: 0.0761 - val_precision_6: 0.3042 - val_recall_8: 0.2216\n",
      "Epoch 95/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.3130 - accuracy: 0.3125 - precision_6: 0.8780 - recall_8: 0.6429Epoch 95 F1 score: 0.2365\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.3203 - accuracy: 0.3379 - precision_6: 0.8173 - recall_8: 0.5960 - val_loss: 0.7932 - val_accuracy: 0.0761 - val_precision_6: 0.3018 - val_recall_8: 0.2216\n",
      "Epoch 96/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.2291 - accuracy: 0.5000 - precision_6: 0.9667 - recall_8: 0.7436Epoch 96 F1 score: 0.2046\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.3101 - accuracy: 0.3392 - precision_6: 0.8275 - recall_8: 0.6182 - val_loss: 0.8195 - val_accuracy: 0.1196 - val_precision_6: 0.3087 - val_recall_8: 0.1850\n",
      "Epoch 97/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.2803 - accuracy: 0.5000 - precision_6: 0.8857 - recall_8: 0.6458Epoch 97 F1 score: 0.2068\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.3015 - accuracy: 0.3488 - precision_6: 0.8413 - recall_8: 0.6318 - val_loss: 0.8326 - val_accuracy: 0.0924 - val_precision_6: 0.3031 - val_recall_8: 0.2062\n",
      "Epoch 98/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.3017 - accuracy: 0.5000 - precision_6: 0.8824 - recall_8: 0.6383Epoch 98 F1 score: 0.2373\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.3045 - accuracy: 0.3474 - precision_6: 0.8189 - recall_8: 0.6240 - val_loss: 0.8449 - val_accuracy: 0.1141 - val_precision_6: 0.3058 - val_recall_8: 0.2139\n",
      "Epoch 99/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.2576 - accuracy: 0.2500 - precision_6: 0.9310 - recall_8: 0.6429Epoch 99 F1 score: 0.1955\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2988 - accuracy: 0.3297 - precision_6: 0.8330 - recall_8: 0.6453 - val_loss: 0.8508 - val_accuracy: 0.1196 - val_precision_6: 0.3253 - val_recall_8: 0.1811\n",
      "Epoch 100/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.2385 - accuracy: 0.4375 - precision_6: 0.9500 - recall_8: 0.5429Epoch 100 F1 score: 0.2188\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2949 - accuracy: 0.3460 - precision_6: 0.8462 - recall_8: 0.6371 - val_loss: 0.8584 - val_accuracy: 0.0870 - val_precision_6: 0.3045 - val_recall_8: 0.2100\n",
      "Epoch 101/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.2751 - accuracy: 0.3125 - precision_6: 0.7273 - recall_8: 0.6316Epoch 101 F1 score: 0.2477\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2885 - accuracy: 0.3420 - precision_6: 0.8288 - recall_8: 0.6472 - val_loss: 0.8217 - val_accuracy: 0.1141 - val_precision_6: 0.3101 - val_recall_8: 0.2486\n",
      "Epoch 102/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.2659 - accuracy: 0.5000 - precision_6: 0.9000 - recall_8: 0.6585Epoch 102 F1 score: 0.2396\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2850 - accuracy: 0.3760 - precision_6: 0.8391 - recall_8: 0.6593 - val_loss: 0.8859 - val_accuracy: 0.0761 - val_precision_6: 0.3101 - val_recall_8: 0.2486\n",
      "Epoch 103/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.3078 - accuracy: 0.1250 - precision_6: 0.7353 - recall_8: 0.6944Epoch 103 F1 score: 0.2034\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2793 - accuracy: 0.3501 - precision_6: 0.8465 - recall_8: 0.6762 - val_loss: 0.8781 - val_accuracy: 0.1141 - val_precision_6: 0.3242 - val_recall_8: 0.2042\n",
      "Epoch 104/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.2966 - accuracy: 0.1875 - precision_6: 0.8333 - recall_8: 0.5814Epoch 104 F1 score: 0.1992\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2762 - accuracy: 0.3501 - precision_6: 0.8526 - recall_8: 0.6699 - val_loss: 0.9004 - val_accuracy: 0.0707 - val_precision_6: 0.3111 - val_recall_8: 0.1888\n",
      "Epoch 105/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.2970 - accuracy: 0.1875 - precision_6: 0.8611 - recall_8: 0.5962Epoch 105 F1 score: 0.2236\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2722 - accuracy: 0.3488 - precision_6: 0.8498 - recall_8: 0.6824 - val_loss: 0.8970 - val_accuracy: 0.0707 - val_precision_6: 0.3204 - val_recall_8: 0.2235\n",
      "Epoch 106/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.2414 - accuracy: 0.2500 - precision_6: 0.9143 - recall_8: 0.7273Epoch 106 F1 score: 0.2074\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2648 - accuracy: 0.3583 - precision_6: 0.8682 - recall_8: 0.6964 - val_loss: 0.8876 - val_accuracy: 0.1359 - val_precision_6: 0.3110 - val_recall_8: 0.1792\n",
      "Epoch 107/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.2009 - accuracy: 0.4375 - precision_6: 0.9767 - recall_8: 0.8077Epoch 107 F1 score: 0.2126\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2642 - accuracy: 0.3760 - precision_6: 0.8561 - recall_8: 0.6950 - val_loss: 0.8909 - val_accuracy: 0.1033 - val_precision_6: 0.2829 - val_recall_8: 0.1908\n",
      "Epoch 108/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.2259 - accuracy: 0.3750 - precision_6: 0.9211 - recall_8: 0.6863Epoch 108 F1 score: 0.2276\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2523 - accuracy: 0.3774 - precision_6: 0.8790 - recall_8: 0.7153 - val_loss: 0.9381 - val_accuracy: 0.0924 - val_precision_6: 0.2986 - val_recall_8: 0.2100\n",
      "Epoch 109/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.2082 - accuracy: 0.3750 - precision_6: 0.9545 - recall_8: 0.7778Epoch 109 F1 score: 0.2153\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2513 - accuracy: 0.3311 - precision_6: 0.8739 - recall_8: 0.7124 - val_loss: 0.9692 - val_accuracy: 0.1413 - val_precision_6: 0.2745 - val_recall_8: 0.2216\n",
      "Epoch 110/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1990 - accuracy: 0.4375 - precision_6: 0.8542 - recall_8: 0.8200Epoch 110 F1 score: 0.2510\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2613 - accuracy: 0.3665 - precision_6: 0.8432 - recall_8: 0.6877 - val_loss: 0.9134 - val_accuracy: 0.0815 - val_precision_6: 0.3198 - val_recall_8: 0.2582\n",
      "Epoch 111/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.2192 - accuracy: 0.4375 - precision_6: 0.9714 - recall_8: 0.7727Epoch 111 F1 score: 0.2359\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.3638 - precision_6: 0.8582 - recall_8: 0.7302 - val_loss: 0.9330 - val_accuracy: 0.0870 - val_precision_6: 0.3025 - val_recall_8: 0.2081\n",
      "Epoch 112/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1966 - accuracy: 0.4375 - precision_6: 0.8824 - recall_8: 0.7692Epoch 112 F1 score: 0.2281\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2368 - accuracy: 0.3638 - precision_6: 0.8856 - recall_8: 0.7326 - val_loss: 0.9577 - val_accuracy: 0.1087 - val_precision_6: 0.2929 - val_recall_8: 0.2139\n",
      "Epoch 113/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.2505 - accuracy: 0.4375 - precision_6: 0.8889 - recall_8: 0.7442Epoch 113 F1 score: 0.2470\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2419 - accuracy: 0.3842 - precision_6: 0.8631 - recall_8: 0.7336 - val_loss: 0.9703 - val_accuracy: 0.1087 - val_precision_6: 0.2886 - val_recall_8: 0.2197\n",
      "Epoch 114/200\n",
      "36/46 [======================>.......] - ETA: 0s - loss: 0.2295 - accuracy: 0.3438 - precision_6: 0.8698 - recall_8: 0.7502Epoch 114 F1 score: 0.2468\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2334 - accuracy: 0.3501 - precision_6: 0.8682 - recall_8: 0.7442 - val_loss: 1.0158 - val_accuracy: 0.0815 - val_precision_6: 0.3050 - val_recall_8: 0.2486\n",
      "Epoch 115/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.3298 - accuracy: 0.4375 - precision_6: 0.7273 - recall_8: 0.6000Epoch 115 F1 score: 0.2262\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2311 - accuracy: 0.3692 - precision_6: 0.8774 - recall_8: 0.7423 - val_loss: 1.0224 - val_accuracy: 0.0924 - val_precision_6: 0.2831 - val_recall_8: 0.2389\n",
      "Epoch 116/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.2758 - accuracy: 0.3125 - precision_6: 0.7963 - recall_8: 0.8113Epoch 116 F1 score: 0.2491\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2350 - accuracy: 0.3610 - precision_6: 0.8784 - recall_8: 0.7534 - val_loss: 0.9824 - val_accuracy: 0.0924 - val_precision_6: 0.3007 - val_recall_8: 0.2370\n",
      "Epoch 117/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1929 - accuracy: 0.3125 - precision_6: 0.8529 - recall_8: 0.8056Epoch 117 F1 score: 0.2044\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2201 - accuracy: 0.3624 - precision_6: 0.8852 - recall_8: 0.7592 - val_loss: 1.0229 - val_accuracy: 0.1250 - val_precision_6: 0.2857 - val_recall_8: 0.1927\n",
      "Epoch 118/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.3688 - accuracy: 0.3125 - precision_6: 0.9259 - recall_8: 0.5208Epoch 118 F1 score: 0.2324\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2233 - accuracy: 0.3651 - precision_6: 0.8790 - recall_8: 0.7679 - val_loss: 1.0140 - val_accuracy: 0.1141 - val_precision_6: 0.3029 - val_recall_8: 0.2177\n",
      "Epoch 119/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1460 - accuracy: 0.6875 - precision_6: 0.9118 - recall_8: 0.8378Epoch 119 F1 score: 0.2086\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2072 - accuracy: 0.4292 - precision_6: 0.8987 - recall_8: 0.7790 - val_loss: 1.0388 - val_accuracy: 0.1033 - val_precision_6: 0.3047 - val_recall_8: 0.1985\n",
      "Epoch 120/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.2551 - accuracy: 0.3750 - precision_6: 1.0000 - recall_8: 0.6275Epoch 120 F1 score: 0.2243\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2062 - accuracy: 0.3815 - precision_6: 0.8987 - recall_8: 0.7876 - val_loss: 1.0399 - val_accuracy: 0.0598 - val_precision_6: 0.2877 - val_recall_8: 0.2023\n",
      "Epoch 121/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.2126 - accuracy: 0.3125 - precision_6: 0.9231 - recall_8: 0.7200Epoch 121 F1 score: 0.2056\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2069 - accuracy: 0.3801 - precision_6: 0.8979 - recall_8: 0.7809 - val_loss: 1.0586 - val_accuracy: 0.1196 - val_precision_6: 0.2883 - val_recall_8: 0.1850\n",
      "Epoch 122/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1545 - accuracy: 0.3750 - precision_6: 0.9706 - recall_8: 0.8049Epoch 122 F1 score: 0.2185\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2002 - accuracy: 0.3951 - precision_6: 0.8981 - recall_8: 0.7867 - val_loss: 1.0477 - val_accuracy: 0.1033 - val_precision_6: 0.2739 - val_recall_8: 0.2042\n",
      "Epoch 123/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1627 - accuracy: 0.3750 - precision_6: 1.0000 - recall_8: 0.8654Epoch 123 F1 score: 0.2610\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1908 - accuracy: 0.3842 - precision_6: 0.9163 - recall_8: 0.8132 - val_loss: 1.0884 - val_accuracy: 0.1196 - val_precision_6: 0.3007 - val_recall_8: 0.2601\n",
      "Epoch 124/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1458 - accuracy: 0.4375 - precision_6: 0.9767 - recall_8: 0.8400Epoch 124 F1 score: 0.2240\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1940 - accuracy: 0.3951 - precision_6: 0.9009 - recall_8: 0.8026 - val_loss: 1.0688 - val_accuracy: 0.1087 - val_precision_6: 0.2791 - val_recall_8: 0.2081\n",
      "Epoch 125/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1983 - accuracy: 0.3750 - precision_6: 0.9394 - recall_8: 0.7045Epoch 125 F1 score: 0.2612\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1925 - accuracy: 0.3896 - precision_6: 0.8984 - recall_8: 0.7939 - val_loss: 1.0978 - val_accuracy: 0.0707 - val_precision_6: 0.2889 - val_recall_8: 0.2466\n",
      "Epoch 126/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.2098 - accuracy: 0.4375 - precision_6: 0.8667 - recall_8: 0.7959Epoch 126 F1 score: 0.2564\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1891 - accuracy: 0.3883 - precision_6: 0.8948 - recall_8: 0.8171 - val_loss: 1.1202 - val_accuracy: 0.1467 - val_precision_6: 0.3099 - val_recall_8: 0.2543\n",
      "Epoch 127/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1668 - accuracy: 0.5000 - precision_6: 0.8947 - recall_8: 0.7727Epoch 127 F1 score: 0.2312\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1731 - accuracy: 0.3910 - precision_6: 0.9172 - recall_8: 0.8234 - val_loss: 1.1214 - val_accuracy: 0.0924 - val_precision_6: 0.3059 - val_recall_8: 0.2216\n",
      "Epoch 128/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1251 - accuracy: 0.5000 - precision_6: 0.9737 - recall_8: 0.8605Epoch 128 F1 score: 0.2333\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1648 - accuracy: 0.4074 - precision_6: 0.9375 - recall_8: 0.8320 - val_loss: 1.1254 - val_accuracy: 0.0870 - val_precision_6: 0.2935 - val_recall_8: 0.2274\n",
      "Epoch 129/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1511 - accuracy: 0.1875 - precision_6: 0.9574 - recall_8: 0.8824Epoch 129 F1 score: 0.2557\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1674 - accuracy: 0.4046 - precision_6: 0.9230 - recall_8: 0.8393 - val_loss: 1.1547 - val_accuracy: 0.0978 - val_precision_6: 0.3170 - val_recall_8: 0.2736\n",
      "Epoch 130/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1931 - accuracy: 0.3125 - precision_6: 0.9231 - recall_8: 0.7660Epoch 130 F1 score: 0.2565\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1650 - accuracy: 0.4183 - precision_6: 0.9288 - recall_8: 0.8369 - val_loss: 1.1492 - val_accuracy: 0.0707 - val_precision_6: 0.2782 - val_recall_8: 0.2659\n",
      "Epoch 131/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1424 - accuracy: 0.3750 - precision_6: 0.9111 - recall_8: 0.9111Epoch 131 F1 score: 0.2557\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1566 - accuracy: 0.3869 - precision_6: 0.9243 - recall_8: 0.8489 - val_loss: 1.1695 - val_accuracy: 0.0761 - val_precision_6: 0.2971 - val_recall_8: 0.2582\n",
      "Epoch 132/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1956 - accuracy: 0.3750 - precision_6: 0.9130 - recall_8: 0.8235Epoch 132 F1 score: 0.2136\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1731 - accuracy: 0.3883 - precision_6: 0.9121 - recall_8: 0.8316 - val_loss: 1.2513 - val_accuracy: 0.0978 - val_precision_6: 0.2786 - val_recall_8: 0.2062\n",
      "Epoch 133/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1922 - accuracy: 0.4375 - precision_6: 0.9412 - recall_8: 0.7273Epoch 133 F1 score: 0.2364\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1734 - accuracy: 0.4101 - precision_6: 0.9037 - recall_8: 0.8292 - val_loss: 1.1706 - val_accuracy: 0.0924 - val_precision_6: 0.2950 - val_recall_8: 0.2274\n",
      "Epoch 134/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1435 - accuracy: 0.4375 - precision_6: 0.9730 - recall_8: 0.8571Epoch 134 F1 score: 0.2336\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1623 - accuracy: 0.4183 - precision_6: 0.9138 - recall_8: 0.8441 - val_loss: 1.2274 - val_accuracy: 0.0815 - val_precision_6: 0.2887 - val_recall_8: 0.2119\n",
      "Epoch 135/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1766 - accuracy: 0.2500 - precision_6: 0.9762 - recall_8: 0.7455Epoch 135 F1 score: 0.2163\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1558 - accuracy: 0.4019 - precision_6: 0.9321 - recall_8: 0.8615 - val_loss: 1.2142 - val_accuracy: 0.1087 - val_precision_6: 0.2789 - val_recall_8: 0.1811\n",
      "Epoch 136/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1827 - accuracy: 0.5625 - precision_6: 0.9688 - recall_8: 0.7750Epoch 136 F1 score: 0.2666\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1462 - accuracy: 0.3951 - precision_6: 0.9357 - recall_8: 0.8639 - val_loss: 1.2579 - val_accuracy: 0.0598 - val_precision_6: 0.3144 - val_recall_8: 0.2659\n",
      "Epoch 137/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0727 - accuracy: 0.5625 - precision_6: 0.9787 - recall_8: 0.9388Epoch 137 F1 score: 0.2539\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1399 - accuracy: 0.3951 - precision_6: 0.9434 - recall_8: 0.8682 - val_loss: 1.2499 - val_accuracy: 0.0815 - val_precision_6: 0.2902 - val_recall_8: 0.2466\n",
      "Epoch 138/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0979 - accuracy: 0.4375 - precision_6: 0.9592 - recall_8: 0.9400Epoch 138 F1 score: 0.2327\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1271 - accuracy: 0.4305 - precision_6: 0.9541 - recall_8: 0.8933 - val_loss: 1.2985 - val_accuracy: 0.1250 - val_precision_6: 0.2864 - val_recall_8: 0.2235\n",
      "Epoch 139/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0860 - accuracy: 0.3750 - precision_6: 0.9811 - recall_8: 0.9630Epoch 139 F1 score: 0.2324\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1292 - accuracy: 0.4005 - precision_6: 0.9514 - recall_8: 0.8880 - val_loss: 1.2978 - val_accuracy: 0.1087 - val_precision_6: 0.2679 - val_recall_8: 0.2312\n",
      "Epoch 140/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0976 - accuracy: 0.3125 - precision_6: 1.0000 - recall_8: 0.9600Epoch 140 F1 score: 0.2505\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1388 - accuracy: 0.4210 - precision_6: 0.9284 - recall_8: 0.8822 - val_loss: 1.3184 - val_accuracy: 0.0870 - val_precision_6: 0.2866 - val_recall_8: 0.2563\n",
      "Epoch 141/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0794 - accuracy: 0.2500 - precision_6: 0.9623 - recall_8: 0.9808Epoch 141 F1 score: 0.2267\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1257 - accuracy: 0.4169 - precision_6: 0.9480 - recall_8: 0.8890 - val_loss: 1.3234 - val_accuracy: 0.0978 - val_precision_6: 0.2734 - val_recall_8: 0.2139\n",
      "Epoch 142/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1559 - accuracy: 0.2500 - precision_6: 0.9778 - recall_8: 0.8800Epoch 142 F1 score: 0.2378\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1269 - accuracy: 0.4074 - precision_6: 0.9427 - recall_8: 0.8890 - val_loss: 1.3176 - val_accuracy: 0.0924 - val_precision_6: 0.2785 - val_recall_8: 0.2447\n",
      "Epoch 143/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1473 - accuracy: 0.3750 - precision_6: 0.9070 - recall_8: 0.9286Epoch 143 F1 score: 0.2462\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1304 - accuracy: 0.4183 - precision_6: 0.9385 - recall_8: 0.8837 - val_loss: 1.3312 - val_accuracy: 0.0707 - val_precision_6: 0.2969 - val_recall_8: 0.2408\n",
      "Epoch 144/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1063 - accuracy: 0.3750 - precision_6: 0.8913 - recall_8: 0.9318Epoch 144 F1 score: 0.2349\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1190 - accuracy: 0.3951 - precision_6: 0.9459 - recall_8: 0.9030 - val_loss: 1.3678 - val_accuracy: 0.0761 - val_precision_6: 0.2765 - val_recall_8: 0.2466\n",
      "Epoch 145/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0763 - accuracy: 0.3750 - precision_6: 0.9762 - recall_8: 0.9535Epoch 145 F1 score: 0.2531\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1113 - accuracy: 0.4223 - precision_6: 0.9532 - recall_8: 0.9044 - val_loss: 1.3897 - val_accuracy: 0.0652 - val_precision_6: 0.2857 - val_recall_8: 0.2505\n",
      "Epoch 146/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1136 - accuracy: 0.3125 - precision_6: 0.9412 - recall_8: 0.9412Epoch 146 F1 score: 0.2618\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1115 - accuracy: 0.4169 - precision_6: 0.9515 - recall_8: 0.9083 - val_loss: 1.4392 - val_accuracy: 0.0870 - val_precision_6: 0.2863 - val_recall_8: 0.2582\n",
      "Epoch 147/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1101 - accuracy: 0.6875 - precision_6: 0.8837 - recall_8: 0.8636Epoch 147 F1 score: 0.2433\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1102 - accuracy: 0.4005 - precision_6: 0.9528 - recall_8: 0.9059 - val_loss: 1.3864 - val_accuracy: 0.0815 - val_precision_6: 0.2727 - val_recall_8: 0.2428\n",
      "Epoch 148/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0810 - accuracy: 0.3750 - precision_6: 1.0000 - recall_8: 0.9348Epoch 148 F1 score: 0.2427\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1028 - accuracy: 0.4251 - precision_6: 0.9643 - recall_8: 0.9136 - val_loss: 1.4127 - val_accuracy: 0.0870 - val_precision_6: 0.2951 - val_recall_8: 0.2331\n",
      "Epoch 149/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1065 - accuracy: 0.5625 - precision_6: 0.9706 - recall_8: 0.8250Epoch 149 F1 score: 0.2363\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1078 - accuracy: 0.4305 - precision_6: 0.9501 - recall_8: 0.9097 - val_loss: 1.3984 - val_accuracy: 0.1087 - val_precision_6: 0.2826 - val_recall_8: 0.2216\n",
      "Epoch 150/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0909 - accuracy: 0.5625 - precision_6: 1.0000 - recall_8: 0.9167Epoch 150 F1 score: 0.2494\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1040 - accuracy: 0.4237 - precision_6: 0.9552 - recall_8: 0.9160 - val_loss: 1.4727 - val_accuracy: 0.1141 - val_precision_6: 0.2969 - val_recall_8: 0.2408\n",
      "Epoch 151/200\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.1001 - accuracy: 0.4514 - precision_6: 0.9615 - recall_8: 0.9222Epoch 151 F1 score: 0.2575\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1001 - accuracy: 0.4496 - precision_6: 0.9617 - recall_8: 0.9218 - val_loss: 1.4296 - val_accuracy: 0.0978 - val_precision_6: 0.2935 - val_recall_8: 0.2505\n",
      "Epoch 152/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0558 - accuracy: 0.5000 - precision_6: 1.0000 - recall_8: 0.9677Epoch 152 F1 score: 0.2258\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0928 - accuracy: 0.4128 - precision_6: 0.9707 - recall_8: 0.9266 - val_loss: 1.5072 - val_accuracy: 0.1033 - val_precision_6: 0.2837 - val_recall_8: 0.2274\n",
      "Epoch 153/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1039 - accuracy: 0.4375 - precision_6: 0.9545 - recall_8: 0.8936Epoch 153 F1 score: 0.2543\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0899 - accuracy: 0.4196 - precision_6: 0.9684 - recall_8: 0.9315 - val_loss: 1.5185 - val_accuracy: 0.0707 - val_precision_6: 0.2867 - val_recall_8: 0.2486\n",
      "Epoch 154/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0785 - accuracy: 0.3750 - precision_6: 0.9286 - recall_8: 0.9750Epoch 154 F1 score: 0.2488\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0830 - accuracy: 0.4278 - precision_6: 0.9715 - recall_8: 0.9373 - val_loss: 1.5109 - val_accuracy: 0.0815 - val_precision_6: 0.2889 - val_recall_8: 0.2466\n",
      "Epoch 155/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0628 - accuracy: 0.5625 - precision_6: 0.9773 - recall_8: 0.9348Epoch 155 F1 score: 0.2378\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0754 - accuracy: 0.4183 - precision_6: 0.9766 - recall_8: 0.9479 - val_loss: 1.5639 - val_accuracy: 0.0924 - val_precision_6: 0.2812 - val_recall_8: 0.2563\n",
      "Epoch 156/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0633 - accuracy: 0.2500 - precision_6: 0.9583 - recall_8: 0.9787Epoch 156 F1 score: 0.2639\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0806 - accuracy: 0.4142 - precision_6: 0.9733 - recall_8: 0.9315 - val_loss: 1.5596 - val_accuracy: 0.1087 - val_precision_6: 0.2980 - val_recall_8: 0.2813\n",
      "Epoch 157/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0940 - accuracy: 0.3125 - precision_6: 0.9556 - recall_8: 0.9348Epoch 157 F1 score: 0.2428\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0851 - accuracy: 0.4155 - precision_6: 0.9667 - recall_8: 0.9373 - val_loss: 1.5901 - val_accuracy: 0.0707 - val_precision_6: 0.2796 - val_recall_8: 0.2505\n",
      "Epoch 158/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0380 - accuracy: 0.3125 - precision_6: 1.0000 - recall_8: 1.0000Epoch 158 F1 score: 0.2503\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0804 - accuracy: 0.4332 - precision_6: 0.9691 - recall_8: 0.9373 - val_loss: 1.5188 - val_accuracy: 0.1087 - val_precision_6: 0.2888 - val_recall_8: 0.2543\n",
      "Epoch 159/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0519 - accuracy: 0.5625 - precision_6: 1.0000 - recall_8: 0.9545Epoch 159 F1 score: 0.2522\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0797 - accuracy: 0.4005 - precision_6: 0.9682 - recall_8: 0.9411 - val_loss: 1.5984 - val_accuracy: 0.1087 - val_precision_6: 0.2933 - val_recall_8: 0.2543\n",
      "Epoch 160/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0565 - accuracy: 0.4375 - precision_6: 1.0000 - recall_8: 0.9636Epoch 160 F1 score: 0.2521\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0691 - accuracy: 0.4046 - precision_6: 0.9788 - recall_8: 0.9585 - val_loss: 1.5511 - val_accuracy: 0.1087 - val_precision_6: 0.2883 - val_recall_8: 0.2428\n",
      "Epoch 161/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0488 - accuracy: 0.5000 - precision_6: 1.0000 - recall_8: 1.0000Epoch 161 F1 score: 0.2700\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.4142 - precision_6: 0.9787 - recall_8: 0.9537 - val_loss: 1.6146 - val_accuracy: 0.0815 - val_precision_6: 0.3060 - val_recall_8: 0.2659\n",
      "Epoch 162/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0522 - accuracy: 0.4375 - precision_6: 1.0000 - recall_8: 0.9500Epoch 162 F1 score: 0.2610\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0652 - accuracy: 0.4332 - precision_6: 0.9775 - recall_8: 0.9633 - val_loss: 1.6016 - val_accuracy: 0.1196 - val_precision_6: 0.2848 - val_recall_8: 0.2678\n",
      "Epoch 163/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0458 - accuracy: 0.5000 - precision_6: 0.9600 - recall_8: 1.0000Epoch 163 F1 score: 0.2577\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0659 - accuracy: 0.4237 - precision_6: 0.9760 - recall_8: 0.9619 - val_loss: 1.6403 - val_accuracy: 0.0924 - val_precision_6: 0.2975 - val_recall_8: 0.2505\n",
      "Epoch 164/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0772 - accuracy: 0.6250 - precision_6: 0.9783 - recall_8: 0.9184Epoch 164 F1 score: 0.2469\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0719 - accuracy: 0.4210 - precision_6: 0.9803 - recall_8: 0.9595 - val_loss: 1.6782 - val_accuracy: 0.0815 - val_precision_6: 0.2926 - val_recall_8: 0.2447\n",
      "Epoch 165/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0631 - accuracy: 0.3750 - precision_6: 0.9767 - recall_8: 0.9545Epoch 165 F1 score: 0.2143\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0808 - accuracy: 0.4550 - precision_6: 0.9722 - recall_8: 0.9445 - val_loss: 1.6820 - val_accuracy: 0.1196 - val_precision_6: 0.2818 - val_recall_8: 0.2004\n",
      "Epoch 166/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0974 - accuracy: 0.5000 - precision_6: 1.0000 - recall_8: 0.8909Epoch 166 F1 score: 0.2234\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.4046 - precision_6: 0.9762 - recall_8: 0.9484 - val_loss: 1.7087 - val_accuracy: 0.0924 - val_precision_6: 0.3046 - val_recall_8: 0.2042\n",
      "Epoch 167/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0853 - accuracy: 0.5000 - precision_6: 1.0000 - recall_8: 0.9130Epoch 167 F1 score: 0.2357\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0572 - accuracy: 0.4237 - precision_6: 0.9833 - recall_8: 0.9691 - val_loss: 1.7204 - val_accuracy: 0.0598 - val_precision_6: 0.2819 - val_recall_8: 0.2254\n",
      "Epoch 168/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0580 - accuracy: 0.6250 - precision_6: 1.0000 - recall_8: 0.9091Epoch 168 F1 score: 0.2677\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0537 - accuracy: 0.4142 - precision_6: 0.9857 - recall_8: 0.9653 - val_loss: 1.7141 - val_accuracy: 0.0761 - val_precision_6: 0.2936 - val_recall_8: 0.2659\n",
      "Epoch 169/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0308 - accuracy: 0.3750 - precision_6: 1.0000 - recall_8: 1.0000Epoch 169 F1 score: 0.2581\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0484 - accuracy: 0.4251 - precision_6: 0.9887 - recall_8: 0.9749 - val_loss: 1.8111 - val_accuracy: 0.0707 - val_precision_6: 0.3064 - val_recall_8: 0.2486\n",
      "Epoch 170/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0351 - accuracy: 0.3125 - precision_6: 1.0000 - recall_8: 0.9643Epoch 170 F1 score: 0.2209\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0498 - accuracy: 0.4142 - precision_6: 0.9887 - recall_8: 0.9720 - val_loss: 1.8233 - val_accuracy: 0.1087 - val_precision_6: 0.2795 - val_recall_8: 0.2235\n",
      "Epoch 171/200\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.0521 - accuracy: 0.4153 - precision_6: 0.9860 - recall_8: 0.9682Epoch 171 F1 score: 0.2374\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0520 - accuracy: 0.4155 - precision_6: 0.9862 - recall_8: 0.9681 - val_loss: 1.7988 - val_accuracy: 0.1196 - val_precision_6: 0.2889 - val_recall_8: 0.2254\n",
      "Epoch 172/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0695 - accuracy: 0.3125 - precision_6: 0.9800 - recall_8: 0.9245Epoch 172 F1 score: 0.2263\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0687 - accuracy: 0.4060 - precision_6: 0.9682 - recall_8: 0.9402 - val_loss: 1.8579 - val_accuracy: 0.0870 - val_precision_6: 0.2790 - val_recall_8: 0.2408\n",
      "Epoch 173/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0722 - accuracy: 0.4375 - precision_6: 0.9804 - recall_8: 0.9615Epoch 173 F1 score: 0.2559\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0783 - accuracy: 0.4060 - precision_6: 0.9620 - recall_8: 0.9406 - val_loss: 1.7906 - val_accuracy: 0.1141 - val_precision_6: 0.2814 - val_recall_8: 0.2678\n",
      "Epoch 174/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0770 - accuracy: 0.2500 - precision_6: 0.9643 - recall_8: 0.9818Epoch 174 F1 score: 0.2393\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0667 - accuracy: 0.4591 - precision_6: 0.9690 - recall_8: 0.9517 - val_loss: 1.7683 - val_accuracy: 0.0978 - val_precision_6: 0.2834 - val_recall_8: 0.2370\n",
      "Epoch 175/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0728 - accuracy: 0.4375 - precision_6: 1.0000 - recall_8: 0.8718Epoch 175 F1 score: 0.2820\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0540 - accuracy: 0.4264 - precision_6: 0.9852 - recall_8: 0.9653 - val_loss: 1.7856 - val_accuracy: 0.0870 - val_precision_6: 0.3092 - val_recall_8: 0.2967\n",
      "Epoch 176/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0345 - accuracy: 0.3750 - precision_6: 0.9762 - recall_8: 1.0000Epoch 176 F1 score: 0.2641\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0656 - accuracy: 0.4455 - precision_6: 0.9673 - recall_8: 0.9566 - val_loss: 1.8642 - val_accuracy: 0.0870 - val_precision_6: 0.3242 - val_recall_8: 0.2505\n",
      "Epoch 177/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0730 - accuracy: 0.3750 - precision_6: 0.9756 - recall_8: 0.9091Epoch 177 F1 score: 0.2543\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0597 - accuracy: 0.4223 - precision_6: 0.9749 - recall_8: 0.9570 - val_loss: 1.8351 - val_accuracy: 0.1033 - val_precision_6: 0.2832 - val_recall_8: 0.2466\n",
      "Epoch 178/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0826 - accuracy: 0.4375 - precision_6: 0.9492 - recall_8: 0.9655Epoch 178 F1 score: 0.2528\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0565 - accuracy: 0.4210 - precision_6: 0.9746 - recall_8: 0.9648 - val_loss: 1.8710 - val_accuracy: 0.0978 - val_precision_6: 0.3020 - val_recall_8: 0.2351\n",
      "Epoch 179/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0354 - accuracy: 0.6250 - precision_6: 1.0000 - recall_8: 0.9744Epoch 179 F1 score: 0.2306\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0468 - accuracy: 0.4237 - precision_6: 0.9805 - recall_8: 0.9725 - val_loss: 1.8997 - val_accuracy: 0.0924 - val_precision_6: 0.2783 - val_recall_8: 0.2177\n",
      "Epoch 180/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0639 - accuracy: 0.3125 - precision_6: 0.9773 - recall_8: 0.9348Epoch 180 F1 score: 0.2626\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 0.3910 - precision_6: 0.9888 - recall_8: 0.9812 - val_loss: 1.8902 - val_accuracy: 0.0870 - val_precision_6: 0.3000 - val_recall_8: 0.2659\n",
      "Epoch 181/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0397 - accuracy: 0.6250 - precision_6: 0.9778 - recall_8: 1.0000Epoch 181 F1 score: 0.2676\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0363 - accuracy: 0.4305 - precision_6: 0.9927 - recall_8: 0.9821 - val_loss: 1.9510 - val_accuracy: 0.1196 - val_precision_6: 0.3073 - val_recall_8: 0.2659\n",
      "Epoch 182/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0137 - accuracy: 0.1875 - precision_6: 1.0000 - recall_8: 1.0000Epoch 182 F1 score: 0.2609\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0348 - accuracy: 0.4005 - precision_6: 0.9951 - recall_8: 0.9855 - val_loss: 1.9550 - val_accuracy: 0.0652 - val_precision_6: 0.2972 - val_recall_8: 0.2909\n",
      "Epoch 183/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0430 - accuracy: 0.5625 - precision_6: 0.9545 - recall_8: 1.0000Epoch 183 F1 score: 0.2668\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0320 - accuracy: 0.4196 - precision_6: 0.9942 - recall_8: 0.9879 - val_loss: 1.9714 - val_accuracy: 0.0924 - val_precision_6: 0.2989 - val_recall_8: 0.2736\n",
      "Epoch 184/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0322 - accuracy: 0.3750 - precision_6: 1.0000 - recall_8: 1.0000Epoch 184 F1 score: 0.2721\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0293 - accuracy: 0.4155 - precision_6: 0.9947 - recall_8: 0.9923 - val_loss: 1.9495 - val_accuracy: 0.1033 - val_precision_6: 0.3107 - val_recall_8: 0.2640\n",
      "Epoch 185/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0205 - accuracy: 0.3750 - precision_6: 1.0000 - recall_8: 1.0000Epoch 185 F1 score: 0.2400\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.4128 - precision_6: 0.9864 - recall_8: 0.9812 - val_loss: 1.9523 - val_accuracy: 0.0707 - val_precision_6: 0.2828 - val_recall_8: 0.2408\n",
      "Epoch 186/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0228 - accuracy: 0.2500 - precision_6: 1.0000 - recall_8: 0.9778Epoch 186 F1 score: 0.2434\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0402 - accuracy: 0.4114 - precision_6: 0.9868 - recall_8: 0.9773 - val_loss: 1.9516 - val_accuracy: 0.0870 - val_precision_6: 0.2938 - val_recall_8: 0.2486\n",
      "Epoch 187/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0270 - accuracy: 0.1875 - precision_6: 1.0000 - recall_8: 1.0000Epoch 187 F1 score: 0.2472\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 0.4210 - precision_6: 0.9898 - recall_8: 0.9826 - val_loss: 2.0268 - val_accuracy: 0.0870 - val_precision_6: 0.2828 - val_recall_8: 0.2697\n",
      "Epoch 188/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0309 - accuracy: 0.5000 - precision_6: 1.0000 - recall_8: 1.0000Epoch 188 F1 score: 0.2501\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0299 - accuracy: 0.4550 - precision_6: 0.9923 - recall_8: 0.9899 - val_loss: 2.0240 - val_accuracy: 0.0761 - val_precision_6: 0.2883 - val_recall_8: 0.2466\n",
      "Epoch 189/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0128 - accuracy: 0.5000 - precision_6: 1.0000 - recall_8: 1.0000Epoch 189 F1 score: 0.2624\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0241 - accuracy: 0.4278 - precision_6: 0.9990 - recall_8: 0.9937 - val_loss: 2.0277 - val_accuracy: 0.1087 - val_precision_6: 0.2987 - val_recall_8: 0.2659\n",
      "Epoch 190/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0243 - accuracy: 0.5625 - precision_6: 1.0000 - recall_8: 1.0000Epoch 190 F1 score: 0.2541\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0234 - accuracy: 0.4183 - precision_6: 0.9961 - recall_8: 0.9942 - val_loss: 2.0723 - val_accuracy: 0.0924 - val_precision_6: 0.2827 - val_recall_8: 0.2582\n",
      "Epoch 191/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0201 - accuracy: 0.2500 - precision_6: 1.0000 - recall_8: 1.0000Epoch 191 F1 score: 0.2544\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0235 - accuracy: 0.4114 - precision_6: 0.9966 - recall_8: 0.9928 - val_loss: 2.0458 - val_accuracy: 0.1033 - val_precision_6: 0.2860 - val_recall_8: 0.2563\n",
      "Epoch 192/200\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.0216 - accuracy: 0.4056 - precision_6: 0.9970 - recall_8: 0.9965Epoch 192 F1 score: 0.2568\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0218 - accuracy: 0.4033 - precision_6: 0.9971 - recall_8: 0.9957 - val_loss: 2.0717 - val_accuracy: 0.0978 - val_precision_6: 0.2986 - val_recall_8: 0.2543\n",
      "Epoch 193/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0181 - accuracy: 0.4375 - precision_6: 1.0000 - recall_8: 1.0000Epoch 193 F1 score: 0.2525\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0177 - accuracy: 0.4128 - precision_6: 0.9976 - recall_8: 0.9986 - val_loss: 2.0787 - val_accuracy: 0.1250 - val_precision_6: 0.2941 - val_recall_8: 0.2505\n",
      "Epoch 194/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0237 - accuracy: 0.6250 - precision_6: 1.0000 - recall_8: 1.0000Epoch 194 F1 score: 0.2439\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0171 - accuracy: 0.4060 - precision_6: 0.9986 - recall_8: 0.9976 - val_loss: 2.1180 - val_accuracy: 0.0707 - val_precision_6: 0.2874 - val_recall_8: 0.2370\n",
      "Epoch 195/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0124 - accuracy: 0.3750 - precision_6: 1.0000 - recall_8: 1.0000Epoch 195 F1 score: 0.2607\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0177 - accuracy: 0.3978 - precision_6: 0.9985 - recall_8: 0.9966 - val_loss: 2.1098 - val_accuracy: 0.1087 - val_precision_6: 0.2897 - val_recall_8: 0.2601\n",
      "Epoch 196/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0274 - accuracy: 0.4375 - precision_6: 1.0000 - recall_8: 1.0000Epoch 196 F1 score: 0.2446\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0149 - accuracy: 0.4142 - precision_6: 0.9995 - recall_8: 0.9981 - val_loss: 2.1653 - val_accuracy: 0.0870 - val_precision_6: 0.2902 - val_recall_8: 0.2293\n",
      "Epoch 197/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0212 - accuracy: 0.3750 - precision_6: 1.0000 - recall_8: 1.0000Epoch 197 F1 score: 0.2616\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0145 - accuracy: 0.4046 - precision_6: 0.9995 - recall_8: 0.9990 - val_loss: 2.1661 - val_accuracy: 0.1033 - val_precision_6: 0.3025 - val_recall_8: 0.2582\n",
      "Epoch 198/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0085 - accuracy: 0.3125 - precision_6: 1.0000 - recall_8: 1.0000Epoch 198 F1 score: 0.2532\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0131 - accuracy: 0.4074 - precision_6: 0.9995 - recall_8: 0.9986 - val_loss: 2.1825 - val_accuracy: 0.0924 - val_precision_6: 0.2940 - val_recall_8: 0.2543\n",
      "Epoch 199/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0109 - accuracy: 0.3750 - precision_6: 1.0000 - recall_8: 1.0000Epoch 199 F1 score: 0.2688\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0203 - accuracy: 0.4264 - precision_6: 0.9961 - recall_8: 0.9923 - val_loss: 2.1823 - val_accuracy: 0.0924 - val_precision_6: 0.2982 - val_recall_8: 0.2948\n",
      "Epoch 200/200\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0217 - accuracy: 0.1875 - precision_6: 0.9792 - recall_8: 1.0000Epoch 200 F1 score: 0.2663\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0376 - accuracy: 0.4346 - precision_6: 0.9835 - recall_8: 0.9759 - val_loss: 2.1745 - val_accuracy: 0.0978 - val_precision_6: 0.3089 - val_recall_8: 0.2678\n",
      "Best F1 score was 0.2820 on epoch 175\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.regularizers import l1_l2\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.metrics import Precision, Recall\n",
    "\n",
    "# 加载数据\n",
    "X = np.load('./data_set/X_train_processed.npy')\n",
    "# X = np.load('./data_set/X_train_filled.npy')\n",
    "\n",
    "Y = np.load('./data_set/Y_train_processed.npy')\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 定义自定义回调以记录和输出最高的 F1 分数\n",
    "class MaxF1ScoreCallback(Callback):\n",
    "    def __init__(self):\n",
    "        super(MaxF1ScoreCallback, self).__init__()\n",
    "        self.max_f1 = 0.0  # 初始化最高 F1 分数\n",
    "        self.best_epoch = 0  # 初始化得分最高的 epoch\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # 预测\n",
    "        pred = (self.model.predict(X_test) > 0.5).astype(int)\n",
    "        # 计算 F1 分数\n",
    "        _f1 = f1_score(Y_test, pred, average='macro')\n",
    "        # 更新最高 F1 分数\n",
    "        if _f1 > self.max_f1:\n",
    "            self.max_f1 = _f1\n",
    "            self.best_epoch = epoch\n",
    "        print(f\"Epoch {epoch + 1} F1 score: {_f1:.4f}\")\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        print(f\"Best F1 score was {self.max_f1:.4f} on epoch {self.best_epoch+1}\")\n",
    "\n",
    "# 定义深度学习模型\n",
    "# def deep_model(feature_dim,label_dim):\n",
    "#     model = Sequential()\n",
    "#     print(\"create model. feature_dim ={}, label_dim ={}\".format(feature_dim, label_dim))\n",
    "#     model.add(Dense(500, activation='relu', input_dim=feature_dim))\n",
    "#     model.add(Dense(100, activation='relu'))\n",
    "#     model.add(Dense(label_dim, activation='sigmoid'))\n",
    "#     model.compile(optimizer='RMSprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#     # model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#     return model\n",
    "def deep_model(feature_dim, label_dim):\n",
    "    model = Sequential()\n",
    "    print(\"create model. feature_dim ={}, label_dim ={}\".format(feature_dim, label_dim))\n",
    "    model.add(Dense(500, activation='relu', input_dim=feature_dim))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(label_dim, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', Precision(), Recall()])\n",
    "    return model\n",
    "\n",
    "# 训练模型并记录最高的 F1 分数\n",
    "def train_deep(X_train, y_train, X_test, y_test):\n",
    "    feature_dim = X_train.shape[1]\n",
    "    label_dim = y_train.shape[1]\n",
    "    model = deep_model(feature_dim, label_dim)\n",
    "    model.summary()\n",
    "    max_f1_callback = MaxF1ScoreCallback()\n",
    "    model.fit(X_train, y_train, batch_size=16, epochs=200, validation_data=(X_test, y_test), callbacks=[max_f1_callback])\n",
    "\n",
    "train_deep(X_train, Y_train, X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def deep_model(feature_dim,label_dim):\n",
    "#     model = Sequential()\n",
    "#     print(\"create model. feature_dim ={}, label_dim ={}\".format(feature_dim, label_dim))\n",
    "#     model.add(Dense(500, activation='relu', input_dim=feature_dim))\n",
    "#     model.add(Dense(100, activation='relu'))\n",
    "#     model.add(Dense(label_dim, activation='sigmoid'))\n",
    "#     model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "# def deep_model(feature_dim, label_dim):\n",
    "#     model = Sequential()\n",
    "#     print(\"create model. feature_dim ={}, label_dim ={}\".format(feature_dim, label_dim))\n",
    "#     model.add(Dense(500, activation='relu', input_dim=feature_dim, kernel_regularizer=l1_l2(l1=0.01, l2=0.01)))\n",
    "#     model.add(Dropout(0.3))\n",
    "#     model.add(Dense(100, activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)))\n",
    "#     model.add(Dropout(0.3))\n",
    "#     model.add(Dense(label_dim, activation='sigmoid'))\n",
    "#     model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Dropout\n",
    "# from keras.regularizers import l1_l2\n",
    "# from keras.callbacks import Callback\n",
    "# from sklearn.metrics import f1_score\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # 加载数据\n",
    "# X = np.load('./data_set/X_train_processed.npy')\n",
    "\n",
    "# Y = np.load('./data_set/Y_train_processed.npy')\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # 定义自定义回调以输出 F1 分数\n",
    "# class F1ScoreCallback(Callback):\n",
    "#     def on_epoch_end(self, epoch, logs={}):\n",
    "#         # 预测\n",
    "#         pred = (self.model.predict(X_test) > 0.5).astype(int)\n",
    "#         # 计算 F1 分数\n",
    "#         _f1 = f1_score(Y_test, pred, average='macro')\n",
    "#         print(f\"Epoch {epoch + 1} F1 score: {_f1:.4f}\")\n",
    "\n",
    "# # # 定义深度学习模型\n",
    "# def deep_model(feature_dim,label_dim):\n",
    "#     model = Sequential()\n",
    "#     print(\"create model. feature_dim ={}, label_dim ={}\".format(feature_dim, label_dim))\n",
    "#     model.add(Dense(500, activation='relu', input_dim=feature_dim))\n",
    "#     model.add(Dense(100, activation='relu'))\n",
    "#     model.add(Dense(label_dim, activation='sigmoid'))\n",
    "#     model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "# # 训练模型并输出每轮的 F1 分数\n",
    "# def train_deep(X_train, y_train, X_test, y_test):\n",
    "#     feature_dim = X_train.shape[1]\n",
    "#     label_dim = y_train.shape[1]\n",
    "#     model = deep_model(feature_dim, label_dim)\n",
    "#     model.summary()\n",
    "#     f1_callback = F1ScoreCallback()\n",
    "#     model.fit(X_train, y_train, batch_size=16, epochs=1000, validation_data=(X_test, y_test), callbacks=[f1_callback])\n",
    "\n",
    "# train_deep(X_train, Y_train, X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential([\n",
    "#     Dense(256, activation='relu', input_shape=(107,)),\n",
    "#     Dropout(0.3),\n",
    "#     Dense(128, activation='relu'),\n",
    "#     Dropout(0.3),\n",
    "#     Dense(64, activation='relu'),\n",
    "#     Dense(11, activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "# model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# history = model.fit(X_train, Y_train, epochs=50, batch_size=64, validation_split=0.1)\n",
    "\n",
    "# Y_pred = model.predict(X_test)\n",
    "# Y_pred_classes = (Y_pred > 0.5).astype(int)\n",
    "\n",
    "# # 分别为每个类别计算指标\n",
    "# for i in range(11):\n",
    "#     acc = accuracy_score(Y_test[:, i], Y_pred_classes[:, i])\n",
    "#     recall = recall_score(Y_test[:, i], Y_pred_classes[:, i])\n",
    "#     f1 = f1_score(Y_test[:, i], Y_pred_classes[:, i])\n",
    "#     cm = confusion_matrix(Y_test[:, i], Y_pred_classes[:, i])\n",
    "#     print(f\"Class {i+1}: Accuracy: {acc}, Recall: {recall}, F1 Score: {f1}\")\n",
    "#     print(f\"Confusion Matrix for Class {i+1}:\")\n",
    "#     print(cm)\n",
    "\n",
    "# # 绘制损失函数图\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(history.history['loss'], label='Training Loss')\n",
    "# plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "# plt.title('Model Loss Over Epochs')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train.astype('float32')\n",
    "# X_test = X_test.astype('float32')\n",
    "# Y_train = Y_train.astype('float32')\n",
    "# Y_test = Y_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential([\n",
    "#     Dense(256, activation='relu', input_shape=(107,)),  # 扩大输入层\n",
    "#     Dropout(0.3),  # Dropout层用于正则化，防止过拟合\n",
    "#     Dense(128, activation='relu'),                       # 增加更多神经元的隐藏层\n",
    "#     Dropout(0.3),  # 另一个Dropout层\n",
    "#     Dense(64, activation='relu'),                        # 继续增加隐藏层的复杂度\n",
    "#     Dense(11, activation='sigmoid')                      # 输出层\n",
    "# ])\n",
    "\n",
    "# model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# history = model.fit(X_train, Y_train, epochs=500, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Y_pred = model.predict(X_test)\n",
    "# Y_pred_classes = (Y_pred > 0.5).astype(int)  # 将概率转换为类别\n",
    "\n",
    "# # 计算评估指标\n",
    "# acc = accuracy_score(Y_test.flatten(), Y_pred_classes.flatten())\n",
    "# recall = recall_score(Y_test.flatten(), Y_pred_classes.flatten(), average='macro')\n",
    "# f1 = f1_score(Y_test.flatten(), Y_pred_classes.flatten(), average='macro')\n",
    "# cm = confusion_matrix(Y_test.flatten(), Y_pred_classes.flatten())\n",
    "\n",
    "# print(f\"Accuracy: {acc}\")\n",
    "# print(f\"Recall: {recall}\")\n",
    "# print(f\"F1 Score: {f1}\")\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(cm)\n",
    "\n",
    "# plt.plot(history.history['loss'], label='Training loss')\n",
    "# plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "# plt.title('Model Loss Over Epochs')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "COMP9417",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
